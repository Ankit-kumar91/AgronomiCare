{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RESNET IMPLEMENTATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Load the pre-trained ResNet50 model without its top layer using ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3)).\n",
    "2. Freeze the layers of the ResNet model to prevent them from being updated during training.\n",
    "3. Add your custom layers on top of the ResNet model.\n",
    "4. Compile the model with an optimizer, loss function, and metrics.\n",
    "5. Preprocess the data and perform data augmentation using ImageDataGenerator.\n",
    "6. Train the model using the training and validation data.\n",
    "7. Finally, make predictions using the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Load the pre-trained ResNet50 model without the top layer (include_top=False)\n",
    "resnet = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Freeze the layers of the ResNet model\n",
    "for layer in resnet.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Add a fully connected layer on top of the ResNet model\n",
    "x = Flatten()(resnet.output)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "output = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "# Create the custom model\n",
    "model = Model(inputs=resnet.input, outputs=output)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Data preprocessing and augmentation\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        'train_data_directory',\n",
    "        target_size=(224, 224),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        'validation_data_directory',\n",
    "        target_size=(224, 224),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical')\n",
    "\n",
    "# Train the model\n",
    "model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=2000 // 32,\n",
    "        epochs=10,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=800 // 32)\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(test_images)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EFFICIENTNET IMPLEMENTATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It follows similar steps as RESNET\n",
    "Just little obvious tweaking of the code, using EfiicientNet in place of ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Flatten, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Load the pre-trained EfficientNetB0 model\n",
    "efficientnet = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Freeze the layers of the EfficientNet model\n",
    "for layer in efficientnet.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Add a fully connected layer on top of the EfficientNet model\n",
    "x = Flatten()(efficientnet.output)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "output = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "# Create the custom model\n",
    "model = Model(inputs=efficientnet.input, outputs=output)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Data preprocessing and augmentation\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        'train_data_directory',\n",
    "        target_size=(224, 224),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        'validation_data_directory',\n",
    "        target_size=(224, 224),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical')\n",
    "\n",
    "# Train the model\n",
    "model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=2000 // 32,\n",
    "        epochs=10,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=800 // 32)\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(test_images)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG16 IMPLEMENTATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: VGG19 follows similar order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Flatten, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Load the pre-trained VGG16 model\n",
    "vgg16 = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Freeze the layers of the VGG16 model\n",
    "for layer in vgg16.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Add a fully connected layer on top of the VGG16 model\n",
    "x = Flatten()(vgg16.output)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "output = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "# Create the custom model\n",
    "model = Model(inputs=vgg16.input, outputs=output)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Data preprocessing and augmentation\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        'train_data_directory',\n",
    "        target_size=(224, 224),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        'validation_data_directory',\n",
    "        target_size=(224, 224),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical')\n",
    "\n",
    "# Train the model\n",
    "model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=2000 // 32,\n",
    "        epochs=10,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=800 // 32)\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(test_images)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DENSENET IMPLEMENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Flatten, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications import DenseNet121\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Load the pre-trained DenseNet121 model\n",
    "densenet = DenseNet121(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Freeze the layers of the DenseNet model\n",
    "for layer in densenet.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Add a fully connected layer on top of the DenseNet model\n",
    "x = Flatten()(densenet.output)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "output = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "# Create the custom model\n",
    "model = Model(inputs=densenet.input, outputs=output)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Data preprocessing and augmentation\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        'train_data_directory',\n",
    "        target_size=(224, 224),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        'validation_data_directory',\n",
    "        target_size=(224, 224),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical')\n",
    "\n",
    "# Train the model\n",
    "model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=2000 // 32,\n",
    "        epochs=10,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=800 // 32)\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(test_images)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INCEPTIONV3 IMPLEMENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Flatten, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications import InceptionV3\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Load the pre-trained InceptionV3 model\n",
    "inception = InceptionV3(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Freeze the layers of the InceptionV3 model\n",
    "for layer in inception.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Add a fully connected layer on top of the InceptionV3 model\n",
    "x = Flatten()(inception.output)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "output = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "# Create the custom model\n",
    "model = Model(inputs=inception.input, outputs=output)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Data preprocessing and augmentation\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        'train_data_directory',\n",
    "        target_size=(224, 224),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        'validation_data_directory',\n",
    "        target_size=(224, 224),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical')\n",
    "\n",
    "# Train the model\n",
    "model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=2000 // 32,\n",
    "        epochs=10,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=800 // 32)\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(test_images)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Xception Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Flatten, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications import Xception\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Load the pre-trained Xception model\n",
    "xception = Xception(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Freeze the layers of the Xception model\n",
    "for layer in xception.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Add a fully connected layer on top of the Xception model\n",
    "x = Flatten()(xception.output)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "output = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "# Create the custom model\n",
    "model = Model(inputs=xception.input, outputs=output)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Data preprocessing and augmentation\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        'train_data_directory',\n",
    "        target_size=(224, 224),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        'validation_data_directory',\n",
    "        target_size=(224, 224),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical')\n",
    "\n",
    "# Train the model\n",
    "model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=2000 // 32,\n",
    "        epochs=10,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=800 // 32)\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(test_images)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
